{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01_experiments_dev — MVTec 画像異常検知（開発\n",
        "\n",
        "本ノートは dev カテゴリのみで設計を確定し、固定パイプライン設定を `assets/fixed_pipeline.json` に出力するためのテンプレートです。\n",
        "- データ取得は anomalib を用いる（AGENTS.md 準拠）\n",
        "- 手法は Mahalanobis / PaDiM を比較\n",
        "- 閾値は dev の test で画像レベル FPR=1% を目標に決定\n",
        "\n",
        "実行順序：Header → Data → Methods → Results → Save JSON/Artifacts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 環境・依存の読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5768fe73",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from sklearn.covariance import ledoit_wolf\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "# anomaly_detectors からコア関数をインポート\n",
        "from anomaly_detectors import (\n",
        "    fit_mahalanobis, all_mahalanobis_scores,\n",
        "    fit_padim, padim_heatmap, all_padim_scores,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65088a9b",
      "metadata": {},
      "source": [
        "## データ取得（anomalib 経由）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "01228e6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 既存の MVTEC_ROOT または datasets/MVTecAD を使用。\n",
        "# 未検出の場合は anomalib によりダウンロード。\n",
        "MVTEC_ROOT = Path(os.environ.get(\"MVTEC_ROOT\", \"datasets/MVTecAD\"))\n",
        "MVTEC_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# anomalib のAPIはバージョンで異なる可能性があるため、例示的に記述。\n",
        "# 実環境の anomalib バージョンに合わせて import と引数を調整してください。\n",
        "try:\n",
        "    from anomalib.data import MVTecAD\n",
        "    datamodule = MVTecAD(root=str(MVTEC_ROOT))\n",
        "    datamodule.prepare_data()  # download if needed\n",
        "    datamodule.setup()\n",
        "except Exception as e:\n",
        "    print(\"[WARN] anomalib のデータ取得セットアップで問題が発生しました。バージョンや引数を確認してください:\\n\", e)\n",
        "\n",
        "assert MVTEC_ROOT.exists(), \"MVTec root not found after anomalib setup.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe101f49",
      "metadata": {},
      "source": [
        "## 実験設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "44d07880",
      "metadata": {},
      "outputs": [],
      "source": [
        "# torchvision のモデル名から学習済みモデルを読み込む関数\n",
        "def load_backbone_from_name(name: str):\n",
        "    try:\n",
        "        from torchvision.models import get_model, get_model_weights\n",
        "        weights = None\n",
        "        try:\n",
        "            weights = get_model_weights(name).DEFAULT  # 学習済みウェイト\n",
        "        except Exception:\n",
        "            pass  # ウェイトが無いモデルはランダム初期化で作る\n",
        "        return get_model(name, weights=weights).eval()\n",
        "    except Exception:\n",
        "        # 旧 API フォールバック（古い torchvision 向け）\n",
        "        if not hasattr(models, name):\n",
        "            raise ValueError(f\"Unknown backbone name: {name}\")\n",
        "        return models.__dict__[name](pretrained=True).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49852b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# dev カテゴリを定義\n",
        "dev_category = \"carpet\" \n",
        "\n",
        "# モデル本体インポート\n",
        "image_size = 256\n",
        "threshold_percentile = 99\n",
        "backbone = \"resnet18\" # \"efficientnet_b0\"\n",
        "model = load_backbone_from_name(backbone)\n",
        "\n",
        "# efficientnet_b0の場合\n",
        "#try:\n",
        "#    from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
        "#    model = efficientnet_b0(weights=EfficientNet_B0_Weights.DEFAULT).eval()\n",
        "#except Exception:\n",
        "#    model = models.efficientnet_b0(pretrained=True).eval()\n",
        "#backbone = model._get_name()\n",
        "#MD_layer = 'flatten'\n",
        "#padim_layers = ['features.6.3.add', 'features.7.0.block.0', 'features.7.0.block.1', 'features.7.0.block.2', 'features.7.0.block.3']\n",
        "\n",
        "# resnet18の場合\n",
        "#try:\n",
        "#    from torchvision.models import resnet18, ResNet18_Weights\n",
        "#    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1).eval() #IMAGENET1K_V1\n",
        "#except Exception:\n",
        "#    model = models.resnet18(pretrained=True).eval()\n",
        "#backbone = model._get_name()\n",
        "\n",
        "MD_layer = 'flatten' # resnet18、 efficientnet_b0 共通\n",
        "padim_layers = [\"layer1.1.relu_1\", \"layer2.1.relu_1\", \"layer3.1.relu_1\"]\n",
        "\n",
        "padim_channel_subsample = 100\n",
        "\n",
        "EXPERIMENT_NAME = f\"{backbone}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b74d370c",
      "metadata": {},
      "source": [
        "## 学習と推論\n",
        "- 各手法で dev の train を用いたクロスバリデーションを実施し、訓練内/訓練外スコアのヒストグラムを確認する。\n",
        "- dev の test で閾値と評価指標（AUROC, F1 など）の関係を可視化する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da5dc09a",
      "metadata": {},
      "source": [
        "### データローダー準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "68fb8377",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Category: carpet\n",
            "[INFO] CV folds: 5\n",
            "  - fold 0: n_train=224, n_val=56\n",
            "  - fold 1: n_train=224, n_val=56\n",
            "  - fold 2: n_train=224, n_val=56\n",
            "  - fold 3: n_train=224, n_val=56\n",
            "  - fold 4: n_train=224, n_val=56\n",
            "[INFO] Dev test size: 117\n",
            "[INFO] Test label distribution: {'color': 19, 'cut': 17, 'good': 28, 'hole': 17, 'metal_contamination': 17, 'thread': 19}\n"
          ]
        }
      ],
      "source": [
        "# Data loading for cross-validation (dev train) and dev test\n",
        "# - Builds KFold train/val DataLoaders using only train/good images.\n",
        "# - Prepares dev test DataLoader with labels (good=0, defect=1).\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Any\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import os\n",
        "\n",
        "# Transforms (ImageNet mean/std)\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "_transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "class ImagePathDataset(Dataset):\n",
        "    \"\"\"Minimal dataset returning (image_tensor, label).\n",
        "\n",
        "    Paths: list of filesystem paths; Labels: list[Any] of same length.\n",
        "    \"\"\"\n",
        "    def __init__(self, paths: List[Path], labels: List[Any], transform=None):\n",
        "        self.paths = [Path(p) for p in paths]\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]\n",
        "        y = self.labels[idx]\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, y\n",
        "\n",
        "def _existing_category_root(category: str) -> Path:\n",
        "    \"\"\"Find an existing MVTec category root among common layouts.\n",
        "    Prefers MVTEC_ROOT, then 'datasets/MVTecAD', then 'MVtec_dataset'.\n",
        "    \"\"\"\n",
        "    candidates = [\n",
        "        MVTEC_ROOT / category,\n",
        "        Path(\"datasets/MVTecAD\") / category,\n",
        "        Path(\"MVtec_dataset\") / category,\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if c.exists():\n",
        "            return c\n",
        "    raise FileNotFoundError(f\"MVTec category not found: {category}\")\n",
        "\n",
        "def _list_images(d: Path) -> List[Path]:\n",
        "    exts = {\".png\", \".jpg\", \".jpeg\"}\n",
        "    if not d.exists():\n",
        "        return []\n",
        "    return sorted([p for p in d.rglob('*') if p.suffix.lower() in exts])\n",
        "\n",
        "def build_cv_and_test_loaders(category: str, k_splits: int = 5, batch_size: int = 32) -> Tuple[list, DataLoader]:\n",
        "    \"\"\"Return (cv_folds, test_loader).\n",
        "\n",
        "    cv_folds: list of dicts with 'train_loader' and 'val_loader'.\n",
        "    test_loader: dev test DataLoader with labels equal to defect types\n",
        "                 (the directory names directly under 'test', e.g., 'good',\n",
        "                 'scratch', 'hole', ...).\n",
        "    \"\"\"\n",
        "    root = _existing_category_root(category)\n",
        "    train_good = _list_images(root / 'train' / 'good')\n",
        "    assert len(train_good) > 0, f\"No train/good images found for {category}\"\n",
        "\n",
        "    # Prepare KFold over indices (all labels are 0 in train).\n",
        "    kf = KFold(n_splits=k_splits, shuffle=True, random_state=0)\n",
        "    base_ds = ImagePathDataset(train_good, [0] * len(train_good), transform=_transform)\n",
        "\n",
        "    num_workers = min(4, os.cpu_count() or 1)\n",
        "    cv_folds = []\n",
        "    for fold_id, (tr_idx, va_idx) in enumerate(kf.split(range(len(train_good)))):\n",
        "        tr_ds = Subset(base_ds, tr_idx)\n",
        "        va_ds = Subset(base_ds, va_idx)\n",
        "        tr_loader = DataLoader(tr_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "        va_loader = DataLoader(va_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "        cv_folds.append({\n",
        "            'fold': fold_id,\n",
        "            'train_loader': tr_loader,\n",
        "            'val_loader': va_loader,\n",
        "            'n_train': len(tr_idx),\n",
        "            'n_val': len(va_idx),\n",
        "        })\n",
        "\n",
        "    # Build dev test loader with labels as defect types (dir names under 'test').\n",
        "    test_dir = root / 'test'\n",
        "    test_paths: List[Path] = []\n",
        "    test_labels: List[str] = []\n",
        "    if test_dir.exists():\n",
        "        # Iterate over subdirectories directly under 'test' (including 'good').\n",
        "        for sub in sorted([d for d in test_dir.iterdir() if d.is_dir()], key=lambda p: p.name):\n",
        "            label = sub.name  # defect type (or 'good')\n",
        "            paths = _list_images(sub)\n",
        "            if paths:\n",
        "                test_paths.extend(paths)\n",
        "                test_labels.extend([label] * len(paths))\n",
        "    assert len(test_paths) > 0, f\"No test images found for {category}\"\n",
        "\n",
        "    test_ds = ImagePathDataset(test_paths, test_labels, transform=_transform)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    return cv_folds, test_loader\n",
        "\n",
        "# Build loaders for the chosen dev category\n",
        "cv_folds, dev_test_loader = build_cv_and_test_loaders(dev_category, k_splits=5, batch_size=32)\n",
        "print(f\"[INFO] Category: {dev_category}\")\n",
        "print(f\"[INFO] CV folds: {len(cv_folds)}\")\n",
        "for f in cv_folds:\n",
        "    print(f\"  - fold {f['fold']}: n_train={f['n_train']}, n_val={f['n_val']}\")\n",
        "from collections import Counter\n",
        "cnt = Counter(dev_test_loader.dataset.labels)\n",
        "print(f\"[INFO] Dev test size: {len(dev_test_loader.dataset)}\")\n",
        "print(f\"[INFO] Test label distribution: {dict(cnt)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fbb268b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"[INFO] Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "results_setup",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Results will be saved under: results/dev/202509202036_resnet18\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "ts = datetime.now().strftime('%Y%m%d%H%M')\n",
        "base_dir = Path(f'results/dev/{ts}_{EXPERIMENT_NAME}')\n",
        "dir_md = base_dir / 'MD'\n",
        "dir_padim = base_dir / 'PaDiM'\n",
        "dir_md.mkdir(parents=True, exist_ok=True); dir_padim.mkdir(parents=True, exist_ok=True)\n",
        "print(f'[INFO] Results will be saved under: {base_dir}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "288a6651",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_histogram(df: pd.DataFrame, ifold: int, save_dir: Path):\n",
        "    # スコアを対数変換\n",
        "    df[\"log_score\"] = np.log1p(df[\"score\"])\n",
        "\n",
        "    # ヒストグラムの描画（Matplotlib）\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "    # 全データでビンを共有（Plotlyのnbins=30相当）\n",
        "    n_bins = 30\n",
        "    bin_edges = np.linspace(df[\"log_score\"].min(), df[\"log_score\"].max(), n_bins + 1)\n",
        "\n",
        "    # 表示順を「train」「val」「good」（テストデータ）優先にし、残りは登場順で\n",
        "    labels_all = df[\"label\"].unique().tolist()\n",
        "    ordered = [\"train\", \"val\", \"good\"] + [l for l in labels_all if l not in (\"train\", \"val\", \"good\")]\n",
        "\n",
        "    for lb in ordered:\n",
        "        vals = df.loc[df[\"label\"] == lb, \"log_score\"].to_numpy()\n",
        "        if len(vals) == 0:\n",
        "            continue\n",
        "        ax.hist(\n",
        "            vals,\n",
        "            bins=bin_edges,\n",
        "            alpha=0.6,\n",
        "            label=lb,\n",
        "            edgecolor=\"black\",\n",
        "            linewidth=0.3,\n",
        "        )\n",
        "\n",
        "    ax.set_title(f\"Anomaly Scores (Fold {ifold})\")\n",
        "    ax.set_xlabel(\"log_score\")\n",
        "    ax.set_ylabel(\"count\")\n",
        "    # ラベル数が多い場合の視認性配慮（必要に応じて調整）\n",
        "    ax.legend(fontsize=8, ncol=2)\n",
        "    fig.tight_layout()\n",
        "\n",
        "    # 画面表示\n",
        "    plt.show()\n",
        "\n",
        "    # 保存（PNG）\n",
        "    out_png = save_dir / f\"fold_{ifold}_hist.png\"\n",
        "    fig.savefig(out_png, dpi=150)\n",
        "    print(f\"[INFO] Saved histogram PNG: {out_png}\")\n",
        "\n",
        "    plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "031692ae",
      "metadata": {},
      "source": [
        "### マハラノビス距離ベースでの異常検知実験"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a3a1b9b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Saved histogram PNG: results/dev/202509202036_resnet18/MD/fold_0_hist.png\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m all_results_MD = {}\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ifold, fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(cv_folds):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     model_state = \u001b[43mfit_mahalanobis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_loader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_node\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMD_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     scores_train = all_mahalanobis_scores(model_state, fold[\u001b[33m\"\u001b[39m\u001b[33mtrain_loader\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     10\u001b[39m     scores_val = all_mahalanobis_scores(model_state, fold[\u001b[33m\"\u001b[39m\u001b[33mval_loader\u001b[39m\u001b[33m\"\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/anomaly_detectors/mahalanobis.py:100\u001b[39m, in \u001b[36mfit_mahalanobis\u001b[39m\u001b[34m(train_loader, backbone, feature_node, cov_estimator, reg_eps, device)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m images, *_ \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     99\u001b[39m     images = images.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     feat = \u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m     feat = _flatten_global(feat)\n\u001b[32m    102\u001b[39m     feats_np.append(feat.cpu().numpy())\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/anomaly_detectors/mahalanobis.py:88\u001b[39m, in \u001b[36mfit_mahalanobis.<locals>._FeatureNodeExtractor.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[33m\"\u001b[39m\u001b[33mfeat\u001b[39m\u001b[33m\"\u001b[39m]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/fx/graph_module.py:848\u001b[39m, in \u001b[36mGraphModule.recompile.<locals>.call_wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/fx/graph_module.py:411\u001b[39m, in \u001b[36m_WrappedCall.__call__\u001b[39m\u001b[34m(self, obj, *args, **kwargs)\u001b[39m\n\u001b[32m    409\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cls_call(obj, *args, **kwargs)\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m e.__traceback__\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m<eval_with_key>.11 from /home/sim_m/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torchvision/models/resnet.py:284 in forward:9\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      7\u001b[39m relu = \u001b[38;5;28mself\u001b[39m.relu(bn1);  bn1 = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      8\u001b[39m maxpool = \u001b[38;5;28mself\u001b[39m.maxpool(relu);  relu = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m layer1_0_conv1 = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m layer1_0_bn1 = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layer1, \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m).bn1(layer1_0_conv1);  layer1_0_conv1 = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     11\u001b[39m layer1_0_relu = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layer1, \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m).relu(layer1_0_bn1);  layer1_0_bn1 = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/work/image-anomaly-detection/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "with warnings.catch_warnings():\n",
        "    # UserWarningを非表示\n",
        "    warnings.filterwarnings('ignore', category=UserWarning) \n",
        "    \n",
        "    # CV 各フォールドで Mahalanobis を学習・評価\n",
        "    all_results_MD = {}\n",
        "    for ifold, fold in enumerate(cv_folds):\n",
        "        model_state = fit_mahalanobis(fold[\"train_loader\"], model, feature_node=MD_layer, device=device)\n",
        "        scores_train = all_mahalanobis_scores(model_state, fold[\"train_loader\"])\n",
        "        scores_val = all_mahalanobis_scores(model_state, fold[\"val_loader\"])\n",
        "        scores_test = all_mahalanobis_scores(model_state, dev_test_loader)\n",
        "\n",
        "        all_results_MD[ifold] = {\n",
        "            \"model_state\": model_state,\n",
        "            \"scores_train\": scores_train,\n",
        "            \"scores_val\": scores_val,\n",
        "            \"scores_test\": scores_test,\n",
        "        }\n",
        "\n",
        "        df_MD = pd.DataFrame({\n",
        "            \"score\": np.r_[scores_train.numpy(), scores_val.numpy(), scores_test.numpy()],\n",
        "            \"label\": ([\"train\"] * len(scores_train) + [\"val\"] * len(scores_val) + dev_test_loader.dataset.labels),\n",
        "        })\n",
        "\n",
        "        plot_histogram(df_MD, ifold, dir_md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0808f484",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 各フォールドのvalデータのスコアのFPR=1%点を計算\n",
        "folds_results_MD = []\n",
        "for ifold, results in all_results_MD.items():\n",
        "    scores_val = results[\"scores_val\"].numpy()\n",
        "    scores_test = results[\"scores_test\"].numpy()\n",
        "    labels_val = np.array([0]*len(scores_val))  # valデータはすべて正常\n",
        "    labels_test = np.array([0 if lbl == \"good\" else 1 for lbl in dev_test_loader.dataset.labels])  # testデータのラベル\n",
        "\n",
        "    # valデータで閾値を決定（FPR=1%点）\n",
        "    threshold = np.percentile(scores_val, threshold_percentile)  # 上位1%を異常とする閾値\n",
        "\n",
        "    # testデータでの異常検知結果を計算\n",
        "    preds_test = (scores_test >= threshold).astype(int)\n",
        "\n",
        "    # 評価指標を計算\n",
        "    auc = roc_auc_score(labels_test, scores_test)\n",
        "    f1 = f1_score(labels_test, preds_test)\n",
        "    folds_results_MD.append({\n",
        "        \"fold\": ifold,\n",
        "        \"threshold\": threshold,\n",
        "        \"auc\": auc,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    print(f\"[Fold {ifold}] Val threshold (FPR=1%): {threshold:.2f}, Test AUC: {auc:.4f}, F1: {f1:.4f}\")\n",
        "# AUC, F1 の平均と標準偏差を計算\n",
        "aucs = [r[\"auc\"] for r in folds_results_MD]\n",
        "f1s = [r[\"f1\"] for r in folds_results_MD]\n",
        "print(f\"[Mahalanobis] Test AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}, F1: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
        "\n",
        "# 保存（サマリーCSV: 各フォールド1行）\n",
        "df_md_summary = pd.DataFrame(folds_results_MD)\n",
        "csv_md = dir_md / 'summary.csv'\n",
        "df_md_summary.to_csv(csv_md, index=False)\n",
        "print(f'[INFO] Saved summary CSV: {csv_md}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "818d2ac9",
      "metadata": {},
      "source": [
        "### PaDiMでの異常検知実験"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b6c079",
      "metadata": {},
      "outputs": [],
      "source": [
        "with warnings.catch_warnings():\n",
        "    # UserWarningを非表示\n",
        "    warnings.filterwarnings('ignore', category=UserWarning) \n",
        "\n",
        "    # CV 各フォールドで PaDiM を学習・評価\n",
        "    all_results_PaDiM = {}\n",
        "    for ifold, fold in enumerate(cv_folds):\n",
        "        model_state = fit_padim(\n",
        "            fold[\"train_loader\"],\n",
        "            model,\n",
        "            layers=padim_layers,\n",
        "            d=padim_channel_subsample,\n",
        "            device=device\n",
        "            )\n",
        "        scores_train = all_padim_scores(model_state, fold[\"train_loader\"])\n",
        "        scores_val = all_padim_scores(model_state, fold[\"val_loader\"])\n",
        "        scores_test, heatmaps_test = all_padim_scores(model_state, dev_test_loader, return_maps=True)\n",
        "\n",
        "        all_results_PaDiM[ifold] = {\n",
        "            \"model_state\": model_state,\n",
        "            \"scores_train\": scores_train,\n",
        "            \"scores_val\": scores_val,\n",
        "            \"scores_test\": scores_test,\n",
        "            \"heatmaps_test\": heatmaps_test,\n",
        "        }\n",
        "\n",
        "        df_PaDiM = pd.DataFrame({\n",
        "            \"score\": np.r_[scores_train.numpy(), scores_val.numpy(), scores_test.numpy()],\n",
        "            \"label\": ([\"train\"] * len(scores_train) + [\"val\"] * len(scores_val) + dev_test_loader.dataset.labels),\n",
        "        })\n",
        "\n",
        "        plot_histogram(df_PaDiM, ifold, dir_padim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0131629",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 評価指標の算出\n",
        "folds_results_PaDiM = []\n",
        "for ifold, results in all_results_PaDiM.items():\n",
        "    scores_val = results[\"scores_val\"].numpy()\n",
        "    scores_test = results[\"scores_test\"].numpy()\n",
        "    labels_val = np.zeros_like(scores_val)  # valは正常のみ\n",
        "    labels_test = np.array([0 if lbl == \"good\" else 1 for lbl in dev_test_loader.dataset.labels])\n",
        "\n",
        "    threshold = np.percentile(scores_val, threshold_percentile)\n",
        "    preds_test = (scores_test >= threshold).astype(int)\n",
        "    auc = roc_auc_score(labels_test, scores_test)\n",
        "    f1 = f1_score(labels_test, preds_test)\n",
        "    folds_results_PaDiM.append({\n",
        "        \"fold\": ifold,\n",
        "        \"threshold\": threshold,\n",
        "        \"auc\": auc,\n",
        "        \"f1\": f1\n",
        "    })\n",
        "    print(\n",
        "        f\"[PaDiM Fold {ifold}] Val threshold (FPR=1%): {threshold:.4f}, \"\n",
        "        f\"Test AUC: {auc:.4f}, F1: {f1:.4f}\"\n",
        "    )\n",
        "# AUC, F1 の平均と標準偏差を計算\n",
        "aucs = [r[\"auc\"] for r in folds_results_PaDiM]\n",
        "f1s = [r[\"f1\"] for r in folds_results_PaDiM]\n",
        "print(f\"[PaDiM] Test AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}, F1: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
        "\n",
        "# 保存（サマリーCSV: 各フォールド1行）\n",
        "df_p_summary = pd.DataFrame(folds_results_PaDiM)\n",
        "csv_p = dir_padim / 'summary.csv'\n",
        "df_p_summary.to_csv(csv_p, index=False)\n",
        "print(f'[INFO] Saved summary CSV: {csv_p}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0147491",
      "metadata": {},
      "source": [
        "#### PaDiMのヒートマップ表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7654b1c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def inv_transform(img_tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "    \"\"\"正規化済み画像テンソルを逆変換してNumPy配列にする\"\"\"\n",
        "    # バッチ次元がある場合は除去\n",
        "    if img_tensor.dim() == 4:\n",
        "        img = img_tensor.squeeze(0)\n",
        "    else:\n",
        "        img = img_tensor\n",
        "\n",
        "    # テンソルを NumPy 配列に変換（形状は [3, H, W]）\n",
        "    img_np = img.cpu().numpy()\n",
        "\n",
        "    # 逆正規化: 各チャネルについて (x * std + mean)\n",
        "    mean = np.array(mean)[:, None, None]\n",
        "    std = np.array(std)[:, None, None]\n",
        "    img_np = img_np * std + mean\n",
        "\n",
        "    # 値を [0, 1] にクリップ\n",
        "    img_np = np.clip(img_np, 0, 1)\n",
        "\n",
        "    # 軸の順番を [3, H, W] → [H, W, 3] に変換\n",
        "    img_np = np.transpose(img_np, (1, 2, 0))\n",
        "\n",
        "    return img_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ffe81c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# テスト画像からランダムに3枚を表示\n",
        "random.seed(0)\n",
        "indices = random.sample(range(len(dev_test_loader.dataset)), 3)\n",
        "heatmaps = [\n",
        "    (idx, all_results_PaDiM[0][\"heatmaps_test\"][idx].numpy())\n",
        "    for idx in indices\n",
        "]\n",
        "\n",
        "vmin = min(hm.min() for _, hm in heatmaps)\n",
        "vmax = max(hm.max() for _, hm in heatmaps)\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(6, 9))\n",
        "for row, (idx, heatmap) in enumerate(heatmaps):\n",
        "    img, lbl = dev_test_loader.dataset[idx]\n",
        "    img = inv_transform(img)\n",
        "    axes[row, 0].imshow(img)\n",
        "    axes[row, 0].set_title(lbl)\n",
        "    axes[row, 0].axis(\"off\")\n",
        "    axes[row, 1].imshow(heatmap, cmap=\"hot\", vmin=vmin, vmax=vmax)\n",
        "    axes[row, 1].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ヒートマップ画像の保存\n",
        "out_png = dir_padim / \"sample_heatmaps.png\"\n",
        "fig.savefig(out_png, dpi=150)\n",
        "print(f\"[INFO] Saved sample heatmaps PNG: {out_png}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e009ea6c",
      "metadata": {},
      "source": [
        "## 設定の保存\n",
        "出力先：assets/fixed_pipeline.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79c5ab4f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# デフォルトではファイルを書き出さない（テンプレートのため）。\n",
        "# 実際に保存したい場合は SAVE_FIXED=True にして実行してください。\n",
        "SAVE_FIXED = True\n",
        "\n",
        "fixed_pipeline = {\n",
        "    \"common\": {\n",
        "        \"image_size\": image_size,\n",
        "        \"backbone\": backbone,\n",
        "        \"threshold_percentile\": threshold_percentile\n",
        "    },\n",
        "    \"mahalanobis\": {\"layer\": MD_layer},\n",
        "    \"padim\": {\"layers\": padim_layers, \"d\": padim_channel_subsample}\n",
        "}\n",
        "\n",
        "assets_dir = Path(\"assets\")\n",
        "assets_dir.mkdir(parents=True, exist_ok=True)\n",
        "cfg_path = assets_dir / \"fixed_pipeline.json\"\n",
        "\n",
        "if SAVE_FIXED:\n",
        "    with cfg_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(fixed_pipeline, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"[INFO] Saved: {cfg_path}\")\n",
        "else:\n",
        "    print(\"[INFO] SAVE_FIXED=False のため assets 固定ファイルはスキップ。\")\n",
        "\n",
        "# 必須: 実行設定を timestamp 付き出力ディレクトリにも保存\n",
        "cfg_out = base_dir / 'fixed_pipeline.json'\n",
        "with cfg_out.open('w', encoding='utf-8') as f:\n",
        "    json.dump(fixed_pipeline, f, indent=2, ensure_ascii=False)\n",
        "print(f\"[INFO] Saved config to: {cfg_out}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 次の手順\n",
        "- 上記のテンプレート関数に実装を追加し、dev の test から閾値を決めて `SAVE_FIXED=True` で JSON を保存。\n",
        "- その後 `02_evaluation_report.ipynb` で eval カテゴリを一発評価。\n",
        "- リーク防止のため、02 ではパラメータ・閾値を変更しないこと。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "image-anomaly-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
