{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "72ef0a38",
      "metadata": {},
      "source": [
        "# 02_evaluation_report — カテゴリ横断評価（Mahalanobis / PaDiM）\n",
        "\n",
        "本ノートでは、指定カテゴリの MVTec AD を対象に、Mahalanobis 距離ベースと PaDiM の2手法で精度を比較します。\n",
        "\n",
        "評価ポリシー:\n",
        "- 共分散（およびPaDiM統計）の推定は、各カテゴリの train/good 全画像を使用（CVは行わない）\n",
        "- モデルの精度評価は test データで実施\n",
        "- 評価カテゴリはリストで与え、順に推論を実行（初期値: leather, tile, wood, bottle）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "939b4040",
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # すべての警告を非表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01d99a4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] anomaly_detectors path: /home/sim_m/work/image-anomaly-detection/anomaly_detectors/__init__.py\n"
          ]
        }
      ],
      "source": [
        "# 依存ライブラリの読み込み\n",
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime, timezone\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# sklearn が無い環境でも動作するよう、読み込みはベストエフォート\n",
        "try:\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "except Exception as e:\n",
        "    roc_auc_score = average_precision_score = f1_score = None\n",
        "    print('[WARN] sklearn.metrics を読み込めませんでした。一部指標が計算できない可能性があります。', e)\n",
        "\n",
        "# anomaly_detectors からコア関数をインポート\n",
        "import importlib, anomaly_detectors\n",
        "importlib.invalidate_caches(); importlib.reload(anomaly_detectors)\n",
        "from anomaly_detectors import (\n",
        "    fit_mahalanobis, all_mahalanobis_scores,\n",
        "    fit_padim, padim_heatmap, all_padim_scores,\n",
        ")\n",
        "\n",
        "RESULTS = Path('runs'); RESULTS.mkdir(parents=True, exist_ok=True)\n",
        "MVTEC_ROOT = Path(os.environ.get('MVTEC_ROOT', 'data/mvtec'))\n",
        "MVTEC_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "print('[INFO] anomaly_detectors path:', anomaly_detectors.__file__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b42001ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 設定（必要に応じて変更）\n",
        "eval_categories = ['leather', 'tile', 'wood', 'bottle']\n",
        "backbone = 'efficientnet_b0'  # 例: 'efficientnet_b0', 'resnet18', 'resnet50' など\n",
        "batch_size = 32\n",
        "image_size = 256\n",
        "num_workers = min(4, os.cpu_count() or 1)\n",
        "fpr_target = 0.01  # 閾値は train/good スコアの上位1% を切るように設定\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1545ebdf",
      "metadata": {},
      "source": [
        "## データユーティリティ（ノートブック内に保持）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ee0f81cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 変換（ImageNet の統計を使用）\n",
        "imagenet_mean = [0.485, 0.456, 0.406]\n",
        "imagenet_std = [0.229, 0.224, 0.225]\n",
        "_transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "class ImagePathDataset(Dataset):\n",
        "    \"\"\"最小限の画像データセット。 (tensor, label) を返す。\n",
        "\n",
        "    Args:\n",
        "        paths (List[Path]): 画像パス群\n",
        "        labels (List[Any]): 同長のラベル\n",
        "        transform: 前処理変換\n",
        "    \"\"\"\n",
        "    def __init__(self, paths, labels, transform=None):\n",
        "        self.paths = [Path(p) for p in paths]\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]; y = self.labels[idx]\n",
        "        img = Image.open(p).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, y\n",
        "\n",
        "from typing import List, Tuple, Any\n",
        "def _existing_category_root(category: str) -> Path:\n",
        "    candidates = [\n",
        "        MVTEC_ROOT / category,\n",
        "        Path('datasets/MVTecAD') / category,\n",
        "        Path('MVtec_dataset') / category,\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if c.exists():\n",
        "            return c\n",
        "    raise FileNotFoundError(f'カテゴリが見つかりません: {category}')\n",
        "\n",
        "def _list_images(d: Path) -> List[Path]:\n",
        "    exts = {'.png', '.jpg', '.jpeg'}\n",
        "    if not d.exists():\n",
        "        return []\n",
        "    return sorted([p for p in d.rglob('*') if p.suffix.lower() in exts])\n",
        "\n",
        "def build_train_and_test_loaders(category: str, batch_size: int = 32) -> Tuple[DataLoader, DataLoader]:\n",
        "    root = _existing_category_root(category)\n",
        "    train_good = _list_images(root / 'train' / 'good')\n",
        "    assert len(train_good) > 0, f'No train/good images: {category}'\n",
        "    # train: 全 good を使用\n",
        "    train_ds = ImagePathDataset(train_good, [0]*len(train_good), transform=_transform)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "    # test: サブディレクトリ名をラベルとして使用（'good'以外は異常）\n",
        "    test_dir = root / 'test'\n",
        "    test_paths, test_labels = [], []\n",
        "    for sub in sorted([d for d in test_dir.iterdir() if d.is_dir()], key=lambda p: p.name):\n",
        "        label = sub.name\n",
        "        paths = _list_images(sub)\n",
        "        if paths:\n",
        "            test_paths.extend(paths)\n",
        "            test_labels.extend([label]*len(paths))\n",
        "    assert len(test_paths) > 0, f'No test images: {category}'\n",
        "    test_ds = ImagePathDataset(test_paths, test_labels, transform=_transform)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f05b9fc",
      "metadata": {},
      "source": [
        "## 指標計算ユーティリティ\n",
        "- 閾値は train/good のスコア分布から FPR=1% を満たす分位点で設定\n",
        "- AUROC/AUPRC はしきい値に依らないため、test スコアと真値で計算\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3082333a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def fpr_threshold_from_neg(scores_neg: np.ndarray, fpr: float = 0.01) -> float:\n",
        "    \"\"\"負例（正常: train/good）のスコアから、指定 FPR を達成するしきい値を返す。\n",
        "    右裾（スコアが高いほど異常）を閾切りするため、(1 - fpr) 分位点を採用。\n",
        "    \"\"\"\n",
        "    fpr = float(np.clip(fpr, 1e-6, 1-1e-6))\n",
        "    return float(np.quantile(scores_neg, 1.0 - fpr))\n",
        "\n",
        "def to_binary_labels(labels: list) -> np.ndarray:\n",
        "    # 'good' を 0、その他（欠陥名）を 1 とする\n",
        "    return np.array([0 if str(y) == 'good' else 1 for y in labels], dtype=np.int64)\n",
        "\n",
        "def compute_metrics(y_true: np.ndarray, y_score: np.ndarray, y_pred: np.ndarray) -> dict:\n",
        "    out = {}\n",
        "    if roc_auc_score is not None:\n",
        "        try:\n",
        "            out['auroc'] = float(roc_auc_score(y_true, y_score))\n",
        "        except Exception as e:\n",
        "            out['auroc'] = None\n",
        "    if average_precision_score is not None:\n",
        "        try:\n",
        "            out['auprc'] = float(average_precision_score(y_true, y_score))\n",
        "        except Exception as e:\n",
        "            out['auprc'] = None\n",
        "    if f1_score is not None:\n",
        "        try:\n",
        "            out['f1'] = float(f1_score(y_true, y_pred))\n",
        "        except Exception as e:\n",
        "            out['f1'] = None\n",
        "    out['acc'] = float((y_true == y_pred).mean())\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3532e99",
      "metadata": {},
      "source": [
        "## カテゴリ評価関数（Mahalanobis / PaDiM）\n",
        "- 各カテゴリで学習（train/good 全使用）→ test 評価\n",
        "- しきい値は train/good の FPR=1% を満たすように設定\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0d7d36e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_category(category: str, backbone: str) -> dict:\n",
        "    # データローダー用意\n",
        "    train_loader, test_loader = build_train_and_test_loaders(category, batch_size=batch_size)\n",
        "\n",
        "    # test の真値（2値）\n",
        "    y_true = to_binary_labels(test_loader.dataset.labels)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # ---- Mahalanobis ----\n",
        "    state_m = fit_mahalanobis(train_loader, backbone=backbone)\n",
        "    scores_train_m = all_mahalanobis_scores(state_m, train_loader).numpy()\n",
        "    thr_m = fpr_threshold_from_neg(scores_train_m, fpr=fpr_target)\n",
        "    scores_test_m = all_mahalanobis_scores(state_m, test_loader).numpy()\n",
        "    y_pred_m = (scores_test_m >= thr_m).astype(np.int64)\n",
        "    results['mahalanobis'] = {\n",
        "        'threshold': float(thr_m),\n",
        "        **compute_metrics(y_true, scores_test_m, y_pred_m),\n",
        "    }\n",
        "\n",
        "    # ---- PaDiM ----\n",
        "    state_p = fit_padim(train_loader, backbone=backbone)\n",
        "    scores_train_p = all_padim_scores(state_p, train_loader).numpy()\n",
        "    thr_p = fpr_threshold_from_neg(scores_train_p, fpr=fpr_target)\n",
        "    scores_test_p = all_padim_scores(state_p, test_loader).numpy()\n",
        "    y_pred_p = (scores_test_p >= thr_p).astype(np.int64)\n",
        "    results['padim'] = {\n",
        "        'threshold': float(thr_p),\n",
        "        **compute_metrics(y_true, scores_test_p, y_pred_p),\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'category': category,\n",
        "        'backbone': backbone,\n",
        "        'results': results,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f19add1",
      "metadata": {},
      "source": [
        "## 実行（カテゴリ一括）\n",
        "- 結果は runs/eval/<category>/metrics_{method}.json にも保存します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "718dee77",
      "metadata": {},
      "outputs": [],
      "source": [
        "all_rows = []\n",
        "for cat in eval_categories:\n",
        "    print(f'[RUN] category={cat}, backbone={backbone}')\n",
        "    out = evaluate_category(cat, backbone)\n",
        "    ts = datetime.now(timezone.utc).isoformat()\n",
        "    # 保存\n",
        "    out_dir = RESULTS / 'eval' / cat\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    for method, metrics in out['results'].items():\n",
        "        with (out_dir / f'metrics_{method}.json').open('w', encoding='utf-8') as f:\n",
        "            json.dump({\n",
        "                'category': cat, 'method': method, 'backbone': backbone,\n",
        "                'timestamp': ts, 'metrics': metrics\n",
        "            }, f, indent=2, ensure_ascii=False)\n",
        "        row = {'category': cat, 'method': method, 'backbone': backbone}\n",
        "        row.update(metrics)\n",
        "        all_rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(all_rows)\n",
        "df_pivot = df.pivot(index='category', columns='method', values='auroc')\n",
        "print('[Summary] AUROC by method/category')\n",
        "display(df_pivot)\n",
        "print('[All metrics]')\n",
        "display(df)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "image-anomaly-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
